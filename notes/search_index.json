[
["index.html", "Capítulo 1 Prefácio", " 1: Coleta a análise das decisões da Suprema Corte Course Notes José de Jesus Filho e Livia Pitelli Última atualização: 07/mai/2019 Capítulo 1 Prefácio Este livro é fruto do trabalho dos autores na pesquisa sobre reclamações ao Supremo Tribunal Federal. A pesquisa subsidiou a tese da autora Lívia Pitelli. Foram realizados vários ajustes para converter o respectivo capítulo da tese em livro/tutorial sobre análise das decisões do Supremo Tribunal Federal. Assim mesmo, o leitor seguramente irá encontrar referências ao trabalho da tese. O texto está em produção, nossa expectativa é melhorá-lo conforme vamos recebendo feedback de alunos e colegas que tenham oportunidade de seguir os scripts contidos ao longo do texto. "],
["metodologia.html", "Capítulo 2 Metodologia ", " Capítulo 2 Metodologia "],
["hipotese.html", "2.1 Hipótese", " 2.1 Hipótese O presente texto apresenta metodologia aplicada para a pesquisa jurispruencial no âmbito do Supremo Tribunal Federal sobre os pedidos de reclamação contra controle concentrado. A metodologia é eminentemente quantitativa e visou oferecer uma explicação das decisões judiciais da Suprema Corte diante do instituto processual da reclamação. A pesquisa está particularmente interessada em saber se as cortes inferiores se contrapôem sistematicamente às decisões do STF e conhecer se houve impacto da alteração legislativa, especificamente a promovida no Código de Processo Civil de 2015, na quantidade de decisões judiciais prolatadas pelos órgãos julgadores do STF, sejam eles singulares ou colegiados. Hipótese 1: A pesquisa buscou testar duas hipóteses. A primeira delas foi verificar se há um descumprimento significativo, por parte dos juízes das cortes inferiores, das decisões do STF. Hipótese 2: A segunda hipótese era saber se com a alteração do CPC promovida em 2015, ao ampliar as hipóteses de cabimento de reclamação, houve alteração no comportamento dos ministros do STF no sentido de aumentar o número. "],
["operacionalizacao.html", "2.2 Operacionalização", " 2.2 Operacionalização Com o fim de verificar as duas hipóteses acima referidas, passamos à sua operacionalização, isto é, passar da da formulação geral sobre comportamento judicial com respeito às reclamações levadas ao STF, para declarações mais específicas, utilizando-se de variáveis mensuráveis e hipotetizar sobre a relação entre elas[@kellstedt2018fundamentals]. A partir da revisão bibligráfica realizada e da consulta jurisprudencial, concluímos é possível testar a primeira hipótese se observarmos que todos ou alguns segmentos do Judiciário têm suas decisões repetidamente cassadas pelo STF em virtude da mesma matéria. Se um ou mais segmentos do Judiciário regularmente tem suas decisões cassadas porque feriram um dos paradigmas do STF, é possível afirmar que é significante esse descumprimento. Por outro lado, se o STF julga constantemente improcedente as reclamações, há aqui uma sugestão de que o problema não se encontra no Judiciário, mas no uso inapropriado da reclamação. Quanto à segunda hipótese, é possível testá-la a partir da comparação da quantidade de provimentos antes e depois da alteração do CPC de 2015. Se o número de provimentos aumentou significativamente com a mudança do CPC, temos uma indicação de que houve efeito da alteração no comportamento da Suprema Corte. Do contrário, se não houve diferença alguma, se o número de decisões procedentes caiu ou se aumentou muito pouco, devemos descartar tal hipótese de que o CPC 2015 gerou algum efeito em termos de concessões de reclamações. Acontece que apenas comparar as decisões favoráveis ou desfavoráveis com o segmento do Judiciário e com o paradigma supostamente violado não é suficiente para alcançarmos uma conclusão confiável. Isto porque o direto aplicado está dentro do campo das ciências sociais, as quais lidam com dados observacionais e não com dados experimentais como ocorre com as pesquisas na área de saúde[@silva2018desenho]. Com dados experimentais o pesquisador possui controle preciso sobre os fatores que causam ou modificam o resultado obtido. Por exemplo, para testar a eficácia de uma vacina, o pesquisador de saúde irá dividir aleatoriamente dois grupos, um que receberá a vacina, o outro que não receberá, chamado grupo de controle. Para testar sua hipótese, é suficiente ele aplicar um teste de associação simples e verificar se as diferenças são significativas ou não[@silva2018desenho]. Por sua vez, as pesquisas em ciências sociais se caracterizam por serem observacionais e a pesquisadora não possui controle apriorístico sobre o efeito de uma variável sobre a outra. Ela deve considerar outros fatores que afetam o resultado para assim isolar o efeito de cada uma das variáveis explicativas sobre o resultado[@silva2018desenho]. Na pesquisa em tela, estamos diante de dados observacionais. O esforço é dirigido em identificar todos os possíveis fatores que influenciam a resposta judicial ao pedido. Nesse sentido, os testes de associação bivariados são inadequados porque irão superdimensionar o efeito de uma variável sobre a outra. A tarefa será de isolar o efeito de cada uma das variáveis explicativas sobre a variável resposta: decisão judicial. Com efeito, podemos supor que o ministro A julgará diferentemente o pedido de reclamação quando se tratar de uma alegada violação a uma súmula do STF do que quando se tratar de uma violação a uma decisão inter partes ou que uma reclamação contra decisão da justiça do trabalho tem maior probabilidade de ter uma resposta favorável quando o ministro é fulano do que quando este é beltrano. Esse tipo de controle somente é posssível realizar por meio das técnicas de regressão, pois o objetivo destas é justamente isolar o efeito de cada uma das variáveis sobre os resultado. Diante disso, a partir da revisão bibliográfica e da leitura de uma amostra das decisões sobre reclamação, foi possível formular um modelo explicativo das decisões judiciais do STF sobre reclamação tomando em conta o segmento do Judiciário alvo da reclamação, o paradigma supostamente violado, o CPC vigente, a matéria tratada, o órgão julgador, a classe processual do “recurso”, se reclamação ou agravo da reclamação e a instância: primeira, segunda ou superior. Todas essas variáveis supostamente têm algum efeito sobre o resultado, de modo que todas elas têm de ingressar na análise porque eventualmente o efeito das variáveis de interesse: segmento, paradigma e CPC vigente é também afetado pelas demais e o próprio resultado: procedente ou improcedente é possivelmente fruto da interação de algumas dessas variáveis. Sendo assim, o modelo explicativo formulado quer saber como variam as chances de um desfecho processual favorável ou desfavorável (variável resposta) ao reclamante tomando em conta as variáveis explicativas acima mencionadas. O quadro abaixo mostra como ficam as hipóteses operacionalizadas em variáveis concretas: "],
["viabilidade.html", "2.3 Viabilidade", " 2.3 Viabilidade Antes de iniciar a pesquisa, realizamos o estudo de viabilidade da pesquisa. O estudo de viabilidade não garante o sucesso ou insucesso da pesquisa, mas reduz significativamente as chances de incorrer em erros e em investimentos desnecessários. Dentre as razões para proceder ao estudo de viabilidade, podemos mencionar a disponibilidade dos dados que se pretende coletar, a adequação dos instrumentos propostos para coletar e analisar tais dados, a correspondência entre os objetivos da pesquisa e os métodos de análise apresentados, a adequação entre os recursos humanos, materiais e financeiros envolvidos e os resultados que se busca alcançar. O estudo da viabilidade é realizado de maneira exploratória e manual. Entramos nos site e varificamos se os dados existem, se estão disponíveis, se há quantidade e variabilidade suficientes para proceder a uma análise quantitativa. Nesse estudo, verificamos inicialmente que a pesquisa jurisprudencial retornava um número muito inferior ao reportado no relatório anual do STF. Diante disso, consultamos a secretaria de informação e esta nos informou que a pesquisa jurisprudencial não retornava todas as decisões. Uma das razões era de que somente as decisões publicadas no Diário de Justiça eram indexadas. Diante disso, optou-se por baixar a lista de decisões proferidas pelo STF, tanto colegiadas quanto monocráticas dos ministros e da presidência, para posteriormente baixar os processos individualmente. "],
["processo-de-coleta-dos-dados.html", "2.4 Processo de coleta dos dados", " 2.4 Processo de coleta dos dados A fim de garantir a reproducibilidade da pesquisa, todo o processo de coleta e análise de dados foi realizado via scripts na linguagem de programação R[@rcore2018]. Scripts são uma sequência de comandos a serem executados pela máquina (computador). Assim, para a coleta dos dados, utilizamos técnicas de respagem de dados (webscraping). Foram montados netbots para baixar as listas anuais de decisões em excel e dessas listas foi possivel obter os números dos processos. Os arquivos em excel foram importados para o R e empilhados numa única tabela. Em seguida, filtramos a tabela para manter somente as decisões relativas à reclamação. Baixamos três grupos de listas, decisões colegiadas, monocráticas e da presidência. A tabela totalizou cerca de 24 mil reclamações distintas. Em seguida montamos os scripts para baixar as páginas htmls com as informações processuais. As páginas do STF são organizadas segundo oito abas: aba principal (detalhes), aba informações, aba partes, aba andamento, aba decisões, aba deslocamentos, aba petições, aba recursos, aba pautas. Cada uma dessas abas consiste em um documento html distinto e para baixá-las não é suficiente realizar apenas uma requisição, mas oito requisições. A primeiras elas (detalhes) obtêm além das informações do cabeçalho, também o número do incidente, isto é, uma indexação interna do STF, chamada incidente. Com esses incidentes podemos realizar novas requisições para extrair os dados das demais abas. Em outras palavras, foram necessárias cerca de 192 mil requisições para acessar todo o conteúdo das respectivas abas. "],
["leitura-dos-html-parseamento.html", "2.5 Leitura dos html (parseamento)", " 2.5 Leitura dos html (parseamento) Após baixar as páginas, montamos scripts para extrair os dados dos htmls e organizá-los em tabelas. Esses scripts foram montados e um subproduto da tese é justamento a criação de um conjunto de funções para automatizar o processo de coleta, leitura e organização dos dados do STF. "],
["organizacao-dos-dados-e-mineracao-dos-textos.html", "2.6 Organização dos dados e mineração dos textos", " 2.6 Organização dos dados e mineração dos textos A fim de deixar os dados prontos para análise, é necessário organizá-los e limpá-los, ou seja, excluir informações excessivas e converter as variáveis para o formato adequado, ou seja, números, caracteres, datas e fatores. Para extrair informações relevantes do texto, utilizamos técnicas de processamento de linguagem natural (NLP, na sigla em inglês), sendo a mais comum delas as expressões regulares ou regex. "],
["analise.html", "2.7 Análise", " 2.7 Análise A análise será realizada considerando as duas hipóteses levantadas. A primeira delas busca responder se há um descumprimento sistemático por parte das cortes inferiores das decisões do STF. Para testar essa hipótese, utilizaremos regressão logística binária com dados em painel, tomando como efeitos fixos as seguintes variáveis tibble::tibble(explicativa=c(&quot;seguimento&quot;,&quot;paradigma&quot;,&quot;reclamante&quot;,&quot;autoridade reclamada&quot;,&quot;cpc15&quot;,&quot;orgao julgador&quot;), categorias=c(&quot;Superior Tribunal de Justiça,\\n Justiça Federal,\\n Justiça do Trabalho,\\n Justiça Eleitoral,\\n Justiça Militar da União,\\n Justiça dos Estados e do Distrito Federal e Territórios,\\n Justiça Militar Estadual&quot;, &quot;Decisão erga omnes,\\n decisão interpartes\\n súmula vinculante&quot;, &quot;pessoa física,\\n pessoa jurídica de direito privado,\\n pessoa jurídica de direito público&quot;, &quot;juiz de primeira instância,\\n juiz de segunda instância,\\n órgão colegiado&quot;, &quot;anterior, posterior&quot;, &quot;ministro,presidente,turma, pleno&quot; ) ) e como grupo ou efeito aleatório o órgão julgador. O modelo segue a seguinte equação: \\[ logit(y) = {\\beta}X + Zu + \\epsilon\\] que no R será modelado da seguinte forma: modelo &lt;- mle4::glmnet(decisao~seguimento+paradigma+reclamante+autoridade+cpc15+orgao_julgador+(1|orgao_julgador)) O modelo seguirá regressão logística binária com efeitos mistos. Segundo o qual, a decisão de procedência ou improcedência será estimada a partir das variáveis explicativas seguimento, paradigma, reclamante, autoridade, cpc15 e orgão julgador. O órgão julgador funcionará tanto como efeito fixo quanto como efeito aleatório. "],
["outros-modelos.html", "2.8 Outros modelos", " 2.8 Outros modelos Além de regressão logística, utilizaremos modelos de aprendizado de máquina (machine learning): floresta aleatória e boosting. "],
["analise-do-efeito-da-lei.html", "2.9 Análise do efeito da lei", " 2.9 Análise do efeito da lei Além desta análise, a pesquisa pretende avaliar o efeito sobre o comportamento judicial. A hipótese é de que com a ampliação de cabimento da reclamação, houve uma redução proporcional das decisões de mérito. Para tanto, iremos utilizar regressão descontínua, a fim de avaliar o efeito da lei sobre as decisões. A proposta é construir um framework para modelar o efeito de leis sobre as decisões judiciais e outros comportamentos. ``` "],
["obtencao-dos-dados.html", "Capítulo 3 Obtenção dos dados", " Capítulo 3 Obtenção dos dados O procedimento abaixo percorre o caminho para baixar, limpar e organizar as decisões do Supremo Tribunal Federal sobre a ação de reclamação. Para realizar este procedimento, utilizou-se um conjunto de rotinas de computador. Esse conjunto de rotinas foi criado dentro do ambiente de programação estatística R. A cada uma das rotinas é dado um nome. Esses nomes são agrupados no aplicativo conhecido como package (pacote de funções) de uma determinada linguagem de programação. A esse pacote também é dado um nome, que no caso se chama stf. Uma vez incorporadas num aplicativo, as rotinas, doravante chamadas de funções, podem ser facilmente reutilizadas, bastando chamá-las pelo nome e informar os argumentos para sua execução dentro de parênteses. A utilização do pacote stf confere replicabilidade e reprodutibilidade à pesquisa. As pesquisas científicas atuais, especialmente as quantitativas, caminham no sentido de garantir a reprodutibilidade, isto é, o caminho percorrido pelo pesquisador no processo de coleta, organização, exploração e análise dos dados, pode ser reproduzido por qualquer outra pesquisadora que tenha familiaridade com o programa utilizado. Reproducibilidade significa usar os mesmos dados e a mesma análise (códigos e modelos) e chegar aos mesmos resultados. Replicabilidade significa aproveitar o mesmo método (código e análise) para aplicá-los a novos dados. O R é um ambiente de programação com código aberto e gratuio. Igualmente, o pacote stf é de livre acesso. Para acessá-lo, basta clicar no seguinte link. Ali se encontram as orientações sobre como utilizá-lo. O pacote stf foi construído pensando em oferecer a acadêmicos de direito, de estatística e de ciência da computação, ferramentas para condução de suas análises sobre a atuação do Supremo Tribunal Federal. "],
["pacotes-necessarios.html", "3.1 Pacotes necessários", " 3.1 Pacotes necessários install.packages(c(&quot;devtools&quot;,&quot;tidyverse&quot;,&quot;janitor&quot;,&quot;quanteda&quot;)) devtools::install_github(&quot;jjesusfilho/stf&quot;) library(stf) library(tidyverse) library(janitor) "],
["baixar-o-acervo-do-stf.html", "3.2 Baixar o acervo do STF", " 3.2 Baixar o acervo do STF O acervo de decisões do STF é composto por três grupos de decisões: monocráticas, correspondentes às decisões individuais dos ministros; colegiadas, correspondentes às decisões das turmas e do pleno; presidente, correspondentes as decisões do presidente. A função seguinte irá baixar todo o acervo de decisões do STF correspondente aos anos indicados e o tipo de decisão. download_stf_collection(decision_type = &quot;monocraticas&quot;,years = 2011:2018,dir = &quot;monocraticas&quot;) download_stf_collection(decision_type = &quot;colegiadas&quot;,years = 2011:2018,dir = &quot;colegiadas&quot;) download_stf_collection(decision_type = &quot;presidente&quot;,years = 2011:2018,dir = &quot;presidente&quot;) "],
["ler-o-acervo.html", "3.3 Ler o acervo", " 3.3 Ler o acervo A função abaixo importa o acervo conforme a classe processual e os anos indicados. Esta função já faz o trabalho inicial de limpar a base de alguns elementos desnecessários e criar uma coluna chamada “incidente”, que é extraída do hyperlink. monocraticas &lt;- read_stf_collection(classes = &quot;Rcl&quot;,years = 2011:2018,dir = &quot;monocraticas&quot;) colegiadas &lt;- read_stf_collection(classes = &quot;Rcl&quot;,years = 2011:2018,dir = &quot;colegiadas&quot;) presidente &lt;- read_stf_collection(classes = &quot;Rcl&quot;,years = 2011:2018,dir = &quot;presidente&quot;) "],
["juncao-das-bases.html", "3.4 Junção das bases", " 3.4 Junção das bases Antes de seguir para os próximos passos, temos de juntar essas três bases e selecionar os processos únicos, de modo a reduzir o número de requisições de processos nos passos seguintes. acervo &lt;- bind_rows(monocraticas,colegiadas, presidente) numeros &lt;- unique(acervo$numero) Os números revelam que houve 22532 reclamações julgadas pelo Supremo Tribunal Federal entre janeiro de 2011 e dezembro de 2018. "],
["remover-colunas-nao-utilizadas.html", "3.5 Remover colunas não utilizadas", " 3.5 Remover colunas não utilizadas Para esta análise específica, somente algumas colunas são de interesse. O procedimento abaixo seleciona tais colunas. acervo &lt;- acervo %&gt;% select(classe,numero,data_autuacao,relator_atual,tipo_decisao,orgao_julgador,data_andamento) "],
["baixar-os-processos.html", "3.6 Baixar os processos", " 3.6 Baixar os processos A maneira mais rápida de baixar os processos seria por meio da coluna incidente. No entanto, notou-se que nem sempre o hiperlink, do qual é extraído o número do incidente, existe. Dessa forma, optou-se utilizar o número do processo na busca. A função abaixo realiza a busca no portal do STF. Tal busca poderá demorar bastante tempo porque são necessárias múltiplas requisições para cada um dos processos, correspondentes aos detalhes básicos que aparecem no topo das informações processuais e às oito abas. Esta função irá criar nove pastas dentro do diretório indicado, correspondentes às oito abas mais a pasta com os detalhes (metadados). Veja que para baixar esses arquivos, é necessário ter lido o acervo antes, pois utilizaremos as colunas classe e número para baixá-los. download_stf_dockets(classes = &quot;Rcl&quot;,docket_number = numeros) "],
["lendo-as-informacoes-processuais-.html", "3.7 Lendo as informações processuais.", " 3.7 Lendo as informações processuais. Das nove pastas, quatro delas são de especial interesse: detalhes, andamentos, partes e informações. Para a nossa análise, as demais são dispensáveis. detalhes &lt;- read_stf_details(path = &quot;detalhes&quot;, plan = &quot;multicore&quot;) andamentos &lt;- read_stf_docket_sheet(path = &quot;andamentos&quot;, plan = &quot;multicore&quot;) informacoes &lt;- read_stf_information(path = &quot;informacoes&quot;, plan = &quot;multicore&quot;) partes &lt;- read_stf_parties(path = &quot;partes&quot;, plan = &quot;multicore&quot;) "]
]
